# üåç Module 03: Nonparametric Regression

**R + Statistical Learning Project | 780 Observations | CO‚ÇÇ Concentrations ‚ûù Temperature Anomalies ‚ûù Climate Insights**

---

## üìö Table of Contents
- [Project Overview](#-project-overview)
- [Tools and Technologies](#-tools-and-technologies)
- [Dataset: Climate Change](#-dataset-climate-change)
- [Nonparametric Methods Overview](#-nonparametric-methods-overview)
- [k-Nearest Neighbours Regression](#-k-nearest-neighbours-regression)
- [Nadaraya-Watson Kernel Regression](#-nadaraya-watson-kernel-regression)
- [Cross-Validation for Parameter Selection](#-cross-validation-for-parameter-selection)
- [Method Comparison](#-method-comparison)
- [Insights & Findings](#-insights--findings)
- [Climate Science Recommendations](#-climate-science-recommendations)
- [Future Work](#-future-work)

---

## üéØ Project Overview

This module analyzes **780 monthly climate observations** to model the relationship between atmospheric CO‚ÇÇ concentrations and global temperature anomalies. Unlike parametric methods that assume specific functional forms, nonparametric regression techniques allow the data to reveal complex, nonlinear patterns that may reflect underlying climate feedback mechanisms.

### The Climate Challenge
```
Atmospheric CO‚ÇÇ (ppm) ‚Üí ? ‚Üí Temperature Anomaly (¬∞C)
      315-450 ppm             Nonlinear Relationship     0.0-2.0¬∞C above baseline
```

### Why Nonparametric Methods?
| **Method** | **Assumptions** | **Flexibility** | **Interpretability** |
|------------|-----------------|-----------------|----------------------|
| Linear Regression | Linear relationship | Low | High |
| Polynomial Regression | Polynomial form | Medium | Medium |
| **k-NN Regression** | Local similarity | High | Low |
| **Kernel Regression** | Smoothness | High | Medium |

**Key Question**: Does the CO‚ÇÇ-temperature relationship exhibit nonlinear patterns that parametric models miss?

---

## üîß Tools and Technologies

| **Category** | **Tools** | **Purpose** |
|--------------|-----------|-------------|
| **k-NN Regression** | caret::knnreg | Nearest neighbours implementation |
| **Kernel Methods** | Custom R function | Nadaraya-Watson estimator |
| **Cross-Validation** | rsample | Parameter tuning (k and bandwidth) |
| **Visualization** | ggplot2, gridExtra | Fitted curves comparison |
| **Data Manipulation** | tidyverse | Data preparation |
| **Reporting** | knitr, kableExtra | Professional tables |

---

## üìä Dataset: Climate Change

The dataset contains **780 monthly observations** of atmospheric CO‚ÇÇ concentrations and corresponding global temperature anomalies.

### Dataset Structure
```
Rows: 780  Columns: 2
```

| **Variable** | **Type** | **Description** | **Range** |
|--------------|----------|-----------------|-----------|
| `co2` | double | Atmospheric CO‚ÇÇ concentration (ppm) | 315 - 450 ppm |
| `temperature_anomaly` | double | Temperature above pre-industrial baseline (¬∞C) | 0.0 - 2.0¬∞C |

### Initial Data Exploration

```r
# Load and examine data
climate_data <- read.csv("data/climate_data.csv")

cat("Dataset dimensions:", nrow(climate_data), "rows x", ncol(climate_data), "columns\n")
glimpse(climate_data)
```
```
Dataset dimensions: 780 rows x 2 columns

Rows: 780
Columns: 2
$ co2                 <dbl> 315.7, 316.5, 317.2, 317.9, 318.5, 319.2, ...
$ temperature_anomaly <dbl> 0.12, 0.15, 0.18, 0.20, 0.22, 0.25, 0.27, ...
```

```r
# Calculate correlation
correlation <- cor(climate_data$co2, climate_data$temperature_anomaly)
cat(sprintf("Pearson correlation: %.3f\n", correlation))
```
```
Pearson correlation: 0.891
```

**Screenshot Suggestion 1**: *Add scatterplot of raw data with linear trend line*
```
üì∏ [Screenshot: climate_scatter_linear.png]
Caption: Figure 1: CO‚ÇÇ concentration vs temperature anomaly with linear fit (r = 0.891)
```

### Visualizing the Relationship

```r
# Create base scatterplot
ggplot(climate_data, aes(x = co2, y = temperature_anomaly)) +
  geom_point(alpha = 0.3, colour = "darkblue") +
  geom_smooth(method = "lm", se = TRUE, colour = "red") +
  labs(
    title = "CO‚ÇÇ Concentration vs Global Temperature Anomaly",
    x = expression(CO[2]~Concentration~(ppm)),
    y = expression(Temperature~Anomaly~(degree*C))
  ) +
  theme_minimal()
```

**Key Observations**:
- Strong positive correlation (r = 0.891)
- Potential nonlinearity at extremes (low and high CO‚ÇÇ)
- Increasing variance at higher CO‚ÇÇ levels
- Possible threshold effects

**Screenshot Suggestion 2**: *Add scatterplot with LOESS smooth to suggest nonlinearity*
```
üì∏ [Screenshot: climate_scatter_loess.png]
Caption: Figure 2: CO‚ÇÇ vs temperature with LOESS smooth revealing potential nonlinear patterns
```

---

## üîß Nonparametric Methods Overview

### What Makes Them "Nonparametric"?

| **Aspect** | **Parametric (e.g., Linear)** | **Nonparametric (k-NN, Kernel)** |
|------------|-------------------------------|----------------------------------|
| **Model Form** | Assumed (e.g., y = Œ≤‚ÇÄ + Œ≤‚ÇÅx) | Determined by data |
| **Parameters** | Fixed number (Œ≤ coefficients) | Varies with data (k, bandwidth) |
| **Flexibility** | Limited by assumed form | Highly flexible |
| **Interpretation** | Clear coefficients | Visual/qualitative |
| **Extrapolation** | Possible (but risky) | Poor‚Äîrelies on local data |

### The Bias-Variance Tradeoff

```
High Bias, Low Variance        Low Bias, High Variance
     (Underfitting)                 (Overfitting)
           ‚Üì                             ‚Üì
    Linear Regression              k=1 k-NN
    Large bandwidth                Small bandwidth
           ‚Üì                             ‚Üì
    Smoother curves                Wiggly curves
    May miss patterns              May fit noise
```

**Screenshot Suggestion 3**: *Add bias-variance tradeoff diagram*
```
üì∏ [Screenshot: bias_variance_tradeoff.png]
Caption: Figure 3: Illustration of bias-variance tradeoff in nonparametric regression
```

---

## üìà k-Nearest Neighbours Regression

### Mathematical Foundation

k-NN regression predicts each point by averaging the response values of the **k closest observations**:

$$\hat{y}(x) = \frac{1}{k}\sum_{i\in \mathcal{N}_k(x)} y_i$$

where $\mathcal{N}_k(x)$ denotes the set of k nearest neighbours to point x.

### 1. Data Preparation

```r
library(caret)
library(rsample)

# Create 75-25 train-test split
set.seed(2024)
data_split <- initial_split(climate_data, prop = 0.75)
train_data <- training(data_split)
test_data <- testing(data_split)

cat(sprintf("Training set: %d observations\n", nrow(train_data)))
cat(sprintf("Test set: %d observations\n", nrow(test_data)))
```
```
Training set: 585 observations
Test set: 195 observations
```

```r
# Prepare matrices for knnreg (requires matrix format)
x_train <- as.matrix(train_data$co2)
y_train <- train_data$temperature_anomaly
x_test <- as.matrix(test_data$co2)
y_test <- test_data$temperature_anomaly

cat(sprintf("x_train dimensions: %d x %d\n", nrow(x_train), ncol(x_train)))
```
```
x_train dimensions: 585 x 1
```

### 2. Testing Different k Values

```r
# Define range of k values to test (from very flexible to very smooth)
k_values <- c(1, 3, 5, 10, 20, 50, 100)

# Initialize storage
knn_results <- data.frame(
  k = integer(),
  train_rmse = numeric(),
  test_rmse = numeric()
)

# Fit models for each k
for(k in k_values) {
  # Fit k-NN model
  knn_model <- knnreg(x = x_train, y = y_train, k = k)
  
  # Make predictions
  train_pred <- predict(knn_model, newdata = x_train)
  test_pred <- predict(knn_model, newdata = x_test)
  
  # Calculate RMSE
  train_rmse <- sqrt(mean((y_train - train_pred)^2))
  test_rmse <- sqrt(mean((y_test - test_pred)^2))
  
  # Store results
  knn_results <- rbind(knn_results,
                       data.frame(k = k, 
                                  train_rmse = train_rmse, 
                                  test_rmse = test_rmse))
}
```

| k | Train RMSE | Test RMSE |
|---|------------|-----------|
| 1 | 0.000 | 0.215 |
| 3 | 0.129 | 0.172 |
| 5 | 0.139 | 0.166 |
| 10 | 0.147 | 0.159 |
| **20** | **0.150** | **0.155** |
| 50 | 0.158 | 0.161 |
| 100 | 0.188 | 0.187 |

**Screenshot Suggestion 4**: *Add line plot of training vs test error across k values*
```
üì∏ [Screenshot: knn_error_vs_k.png]
Caption: Figure 4: Training and test RMSE as function of k (bias-variance tradeoff visible)
```

### 3. Interpreting the Results

```r
# Identify optimal k
optimal_k <- knn_results$k[which.min(knn_results$test_rmse)]
cat(sprintf("Optimal k: %d (Test RMSE: %.3f)\n", 
            optimal_k, min(knn_results$test_rmse)))
```
```
Optimal k: 20 (Test RMSE: 0.155)
```

**Key Observations**:
- **k = 1**: Train RMSE = 0 (perfect fit, severe overfitting), Test RMSE = 0.215
- **k = 20**: Best test performance, balanced bias-variance
- **k = 100**: Test RMSE increases (underfitting), Train RMSE increases (bias)

**What happens as k increases?**
- Small k: Low bias, high variance (overfitting)
- Large k: High bias, low variance (underfitting)
- Optimal k: Minimizes test error

### 4. Visualizing k-NN Predictions

```r
# Create grid of CO2 values for smooth prediction curves
co2_grid <- seq(min(climate_data$co2), max(climate_data$co2), length.out = 200)
co2_grid_matrix <- as.matrix(co2_grid)

# Generate predictions for selected k values
k_selected <- c(1, 10, 50)
predictions_list <- list()

for(k in k_selected) {
  knn_model <- knnreg(x = x_train, y = y_train, k = k)
  knn_pred <- predict(knn_model, newdata = co2_grid_matrix)
  
  predictions_list[[as.character(k)]] <- data.frame(
    co2 = co2_grid,
    prediction = knn_pred,
    k = as.factor(k)
  )
}

# Combine predictions
knn_all_predictions <- bind_rows(predictions_list)

# Plot with original data
ggplot() +
  geom_point(data = climate_data, 
             aes(x = co2, y = temperature_anomaly),
             alpha = 0.2, colour = "gray50") +
  geom_line(data = knn_all_predictions,
            aes(x = co2, y = prediction, colour = k),
            size = 1.2) +
  scale_colour_manual(values = c("1" = "red", "10" = "blue", "50" = "green")) +
  labs(
    title = "k-NN Regression: Effect of k on Fitted Curves",
    x = expression(CO[2]~Concentration~(ppm)),
    y = expression(Temperature~Anomaly~(degree*C)),
    colour = "Number of\nNeighbours (k)"
  ) +
  theme_minimal()
```

**Screenshot Suggestion 5**: *Add plot showing k-NN fits for different k values*
```
üì∏ [Screenshot: knn_fits_comparison.png]
Caption: Figure 5: k-NN fitted curves for k=1 (overfitting), k=10 (balanced), and k=50 (oversmoothed)
```

### 5. Understanding the k-NN Behaviour

| **k Value** | **Curve Characteristic** | **Interpretation** |
|-------------|--------------------------|-------------------|
| **k = 1** | Highly wiggly, passes through every point | Fitting noise, not signal |
| **k = 10** | Smooth but follows data patterns | Good balance |
| **k = 50** | Overly smooth, misses local patterns | Underfitting |

---

## üéØ Nadaraya-Watson Kernel Regression

### Mathematical Foundation

The Nadaraya-Watson estimator uses **kernel weighting** to give closer neighbours greater influence:

$$\hat{y}(x) = \frac{\sum_{i=1}^{n} K_h(x - x_i) y_i}{\sum_{i=1}^{n} K_h(x - x_i)}$$

where $K_h(u) = \frac{1}{h} K\left(\frac{u}{h}\right)$ and $h$ is the **bandwidth parameter**.

### 1. Implementing the Gaussian Kernel

```r
# Gaussian kernel function
gaussian_kernel <- function(u) {
  (1 / sqrt(2 * pi)) * exp(-(u^2) / 2)
}

# Test the kernel
test_values <- c(-3, -2, -1, 0, 1, 2, 3)
kernel_weights <- gaussian_kernel(test_values)

data.frame(
  distance = test_values,
  weight = round(kernel_weights, 4)
)
```

| distance | weight |
|----------|--------|
| -3 | 0.0044 |
| -2 | 0.0540 |
| -1 | 0.2420 |
| 0 | 0.3989 |
| 1 | 0.2420 |
| 2 | 0.0540 |
| 3 | 0.0044 |

**Screenshot Suggestion 6**: *Add plot of Gaussian kernel function*
```
üì∏ [Screenshot: gaussian_kernel.png]
Caption: Figure 6: Gaussian kernel function showing weight decay with distance
```

### 2. Nadaraya-Watson Implementation

```r
# Custom Nadaraya-Watson estimator
nadaraya_watson <- function(x_train, y_train, x_test, bandwidth) {
  # Initialize predictions vector
  predictions <- numeric(length(x_test))
  
  # Loop through each test point
  for(i in 1:length(x_test)) {
    # Calculate distances from test point to all training points
    distances <- x_test[i] - x_train
    
    # Calculate standardised distances (u = distance / bandwidth)
    u <- distances / bandwidth
    
    # Apply Gaussian kernel to get weights
    weights <- gaussian_kernel(u)
    
    # Calculate weighted average (Nadaraya-Watson formula)
    # Numerator: sum of weighted responses
    # Denominator: sum of weights
    if(sum(weights) > 0) {
      predictions[i] <- sum(weights * y_train) / sum(weights)
    } else {
      # If all weights are zero, use overall mean
      predictions[i] <- mean(y_train)
    }
  }
  
  return(predictions)
}
```

### 3. Silverman's Rule of Thumb for Bandwidth

```r
# Calculate Silverman's rule-of-thumb bandwidth
n <- length(y_train)
sigma <- sd(as.vector(x_train))
iqr <- IQR(as.vector(x_train))

h_silverman <- 0.9 * min(sigma, iqr / 1.34) * n^(-1/5)
cat(sprintf("Silverman's rule-of-thumb bandwidth: %.2f\n", h_silverman))
```
```
Silverman's rule-of-thumb bandwidth: 6.75
```

### 4. Testing Different Bandwidths

```r
# Test multiples of Silverman's bandwidth
bandwidth_values <- h_silverman * c(0.5, 1, 2, 3, 5)

# Initialize storage
nw_results <- data.frame(
  bandwidth = numeric(),
  train_rmse = numeric(),
  test_rmse = numeric()
)

# Fit models for each bandwidth
for(bw in bandwidth_values) {
  # Predict training set
  train_pred <- nadaraya_watson(
    x_train = as.vector(x_train),
    y_train = y_train,
    x_test = as.vector(x_train),
    bandwidth = bw
  )
  
  # Predict test set
  test_pred <- nadaraya_watson(
    x_train = as.vector(x_train),
    y_train = y_train,
    x_test = as.vector(x_test),
    bandwidth = bw
  )
  
  # Calculate RMSE
  train_rmse <- sqrt(mean((y_train - train_pred)^2))
  test_rmse <- sqrt(mean((y_test - test_pred)^2))
  
  # Store results
  nw_results <- rbind(nw_results,
                      data.frame(bandwidth = bw,
                                 train_rmse = train_rmse,
                                 test_rmse = test_rmse))
}
```

| bandwidth | Train RMSE | Test RMSE |
|-----------|------------|-----------|
| 3.37 | 0.152 | 0.156 |
| 6.75 | 0.159 | 0.162 |
| 13.49 | 0.183 | 0.186 |
| 20.24 | 0.219 | 0.220 |
| 33.73 | 0.287 | 0.281 |

**Screenshot Suggestion 7**: *Add line plot of training vs test error across bandwidths*
```
üì∏ [Screenshot: nw_error_vs_bandwidth.png]
Caption: Figure 7: Training and test RMSE as function of bandwidth (h)
```

### 5. Identifying Optimal Bandwidth

```r
optimal_h <- nw_results$bandwidth[which.min(nw_results$test_rmse)]
cat(sprintf("Optimal bandwidth: %.2f (Test RMSE: %.3f)\n", 
            optimal_h, min(nw_results$test_rmse)))
```
```
Optimal bandwidth: 3.37 (Test RMSE: 0.156)
```

**Key Observations**:
- **Small bandwidth (h = 3.37)**: Best test performance, captures local patterns
- **Medium bandwidth (h = 6.75)**: Slightly smoother, test RMSE increases
- **Large bandwidth (h = 33.73)**: Overly smooth, misses important patterns

### 6. Visualizing Nadaraya-Watson Predictions

```r
# Generate predictions for selected bandwidths
h_selected <- h_silverman * c(0.5, 1, 3)
nw_predictions_list <- list()

for(h in h_selected) {
  nw_pred <- nadaraya_watson(
    x_train = as.vector(x_train),
    y_train = y_train,
    x_test = co2_grid,
    bandwidth = h
  )
  
  nw_predictions_list[[as.character(round(h, 1))]] <- data.frame(
    co2 = co2_grid,
    prediction = nw_pred,
    bandwidth = as.factor(round(h, 1))
  )
}

# Combine predictions
nw_all_predictions <- bind_rows(nw_predictions_list)

# Plot
ggplot() +
  geom_point(data = climate_data, 
             aes(x = co2, y = temperature_anomaly),
             alpha = 0.2, colour = "gray50") +
  geom_line(data = nw_all_predictions,
            aes(x = co2, y = prediction, colour = bandwidth),
            size = 1.2) +
  scale_colour_manual(values = c("3.4" = "red", "6.7" = "blue", "20.2" = "green")) +
  labs(
    title = "Nadaraya-Watson Regression: Effect of Bandwidth",
    x = expression(CO[2]~Concentration~(ppm)),
    y = expression(Temperature~Anomaly~(degree*C)),
    colour = "Bandwidth (h)"
  ) +
  theme_minimal()
```

**Screenshot Suggestion 8**: *Add plot showing NW fits for different bandwidths*
```
üì∏ [Screenshot: nw_fits_comparison.png]
Caption: Figure 8: Nadaraya-Watson fitted curves for h=3.4 (optimal), h=6.7 (medium), and h=20.2 (oversmoothed)
```

### 7. Understanding Bandwidth Effects

| **Bandwidth** | **Curve Characteristic** | **Interpretation** |
|---------------|--------------------------|-------------------|
| **h = 3.37** | Follows local patterns | Good balance, optimal |
| **h = 6.75** | Smoother, some detail lost | Slightly underfitting |
| **h = 20.24** | Nearly linear, misses curvature | Severe underfitting |

---

## üîÑ Cross-Validation for Parameter Selection

### 1. Cross-Validation for k-NN

```r
# Set up 10-fold cross-validation
set.seed(2024)
cv_folds <- vfold_cv(climate_data, v = 10)

# Define range of k values
k_range <- c(1, 2, 3, 5, 7, 10, 15, 20, 30, 50, 75, 100)

# Initialize storage
cv_results <- data.frame(
  k = integer(),
  fold = integer(),
  rmse = numeric()
)

# Perform cross-validation
for(k in k_range) {
  for(i in 1:nrow(cv_folds)) {
    # Extract fold data
    train_fold <- analysis(cv_folds$splits[[i]])
    test_fold <- assessment(cv_folds$splits[[i]])
    
    # Prepare matrices
    x_train_fold <- as.matrix(train_fold$co2)
    y_train_fold <- train_fold$temperature_anomaly
    x_test_fold <- as.matrix(test_fold$co2)
    
    # Fit k-NN model
    knn_model <- knnreg(x = x_train_fold, y = y_train_fold, k = k)
    
    # Make predictions
    knn_pred <- predict(knn_model, newdata = x_test_fold)
    
    # Calculate RMSE
    fold_rmse <- sqrt(mean((test_fold$temperature_anomaly - knn_pred)^2))
    
    # Store results
    cv_results <- rbind(cv_results,
                        data.frame(k = k, fold = i, rmse = fold_rmse))
  }
}

# Calculate mean CV error for each k
cv_summary <- cv_results %>%
  group_by(k) %>%
  summarise(
    mean_rmse = mean(rmse),
    sd_rmse = sd(rmse),
    .groups = 'drop'
  )
```

| k | Mean CV RMSE | SD RMSE |
|---|--------------|---------|
| 1 | 0.219 | 0.019 |
| 2 | 0.193 | 0.011 |
| 3 | 0.180 | 0.013 |
| 5 | 0.169 | 0.017 |
| 7 | 0.165 | 0.015 |
| 10 | 0.163 | 0.015 |
| 15 | 0.159 | 0.015 |
| **20** | **0.158** | **0.014** |
| 30 | 0.156 | 0.014 |
| 50 | 0.158 | 0.014 |
| 75 | 0.166 | 0.017 |
| 100 | 0.179 | 0.022 |

```r
# Identify optimal k from CV
optimal_k_cv <- cv_summary$k[which.min(cv_summary$mean_rmse)]
cat(sprintf("Optimal k (CV): %d (CV RMSE: %.4f)\n", 
            optimal_k_cv, min(cv_summary$mean_rmse)))
```
```
Optimal k (CV): 30 (CV RMSE: 0.1565)
```

**Screenshot Suggestion 9**: *Add CV error plot with error bars for k-NN*
```
üì∏ [Screenshot: knn_cv_results.png]
Caption: Figure 9: 10-fold cross-validation results for k-NN showing mean RMSE ¬± 1 SD
```

### 2. Cross-Validation for Nadaraya-Watson

```r
# Define range of bandwidth values (multiples of Silverman)
h_range <- h_silverman * c(0.3, 0.5, 0.7, 1, 1.5, 2, 3, 5, 7)

# Initialize storage
nw_cv_results <- data.frame(
  bandwidth = numeric(),
  fold = integer(),
  rmse = numeric()
)

# Perform cross-validation
for(h in h_range) {
  for(i in 1:nrow(cv_folds)) {
    # Extract fold data
    train_fold <- analysis(cv_folds$splits[[i]])
    test_fold <- assessment(cv_folds$splits[[i]])
    
    # Make predictions using Nadaraya-Watson
    nw_pred <- nadaraya_watson(
      x_train = train_fold$co2,
      y_train = train_fold$temperature_anomaly,
      x_test = test_fold$co2,
      bandwidth = h
    )
    
    # Calculate RMSE
    fold_rmse <- sqrt(mean((test_fold$temperature_anomaly - nw_pred)^2))
    
    # Store results
    nw_cv_results <- rbind(nw_cv_results,
                           data.frame(bandwidth = h, fold = i, rmse = fold_rmse))
  }
}

# Calculate mean CV error for each bandwidth
nw_cv_summary <- nw_cv_results %>%
  group_by(bandwidth) %>%
  summarise(
    mean_rmse = mean(rmse),
    sd_rmse = sd(rmse),
    .groups = 'drop'
  )
```

| bandwidth | Mean CV RMSE | SD RMSE |
|-----------|--------------|---------|
| 2.02 | **0.154** | 0.013 |
| 3.37 | 0.155 | 0.013 |
| 4.72 | 0.156 | 0.012 |
| 6.75 | 0.160 | 0.013 |
| 10.12 | 0.169 | 0.014 |
| 13.49 | 0.183 | 0.017 |
| 20.24 | 0.218 | 0.022 |
| 33.73 | 0.285 | 0.030 |
| 47.22 | 0.317 | 0.033 |

```r
# Identify optimal bandwidth from CV
optimal_h_cv <- nw_cv_summary$bandwidth[which.min(nw_cv_summary$mean_rmse)]
cat(sprintf("Optimal bandwidth (CV): %.2f (CV RMSE: %.4f)\n", 
            optimal_h_cv, min(nw_cv_summary$mean_rmse)))
```
```
Optimal bandwidth (CV): 2.02 (CV RMSE: 0.1542)
```

**Screenshot Suggestion 10**: *Add CV error plot with error bars for Nadaraya-Watson*
```
üì∏ [Screenshot: nw_cv_results.png]
Caption: Figure 10: 10-fold cross-validation results for Nadaraya-Watson showing mean RMSE ¬± 1 SD
```

---

## üìä Method Comparison

### 1. Compare All Methods

```r
# Fit optimal k-NN model
knn_optimal <- knnreg(x = x_train, y = y_train, k = optimal_k_cv)
knn_optimal_pred <- predict(knn_optimal, newdata = x_test)
knn_optimal_rmse <- sqrt(mean((y_test - knn_optimal_pred)^2))

# Fit optimal Nadaraya-Watson model
nw_optimal_pred <- nadaraya_watson(
  x_train = as.vector(x_train),
  y_train = y_train,
  x_test = as.vector(x_test),
  bandwidth = optimal_h_cv
)
nw_optimal_rmse <- sqrt(mean((y_test - nw_optimal_pred)^2))

# Fit linear regression for comparison
ols_model <- lm(temperature_anomaly ~ co2, data = train_data)
ols_pred <- predict(ols_model, newdata = test_data)
ols_rmse <- sqrt(mean((y_test - ols_pred)^2))

# Fit polynomial regression (degree 3) for comparison
poly_model <- lm(temperature_anomaly ~ poly(co2, 3), data = train_data)
poly_pred <- predict(poly_model, newdata = test_data)
poly_rmse <- sqrt(mean((y_test - poly_pred)^2))

# Create comparison table
comparison_table <- data.frame(
  Method = c("Linear Regression", "Polynomial (deg 3)", 
             "k-NN Regression", "Nadaraya-Watson"),
  Test_RMSE = c(ols_rmse, poly_rmse, knn_optimal_rmse, nw_optimal_rmse),
  Parameters = c("2 (intercept + slope)", 
                 "4 coefficients",
                 paste("k =", optimal_k_cv),
                 paste("h =", round(optimal_h_cv, 1)))
) %>%
  arrange(Test_RMSE)
```

| Method | Test RMSE | Parameters |
|--------|-----------|------------|
| **Polynomial (deg 3)** | **0.155** | 4 coefficients |
| **Nadaraya-Watson** | **0.155** | h = 2.0 |
| k-NN Regression | 0.157 | k = 30 |
| Linear Regression | 0.298 | 2 (intercept + slope) |

**Screenshot Suggestion 11**: *Add bar chart comparing all method RMSEs*
```
üì∏ [Screenshot: all_methods_comparison.png]
Caption: Figure 11: Test RMSE comparison across all regression methods
```

### 2. Visual Comparison of Fitted Curves

```r
# Generate predictions for all methods on grid
ols_grid_pred <- predict(ols_model, newdata = data.frame(co2 = co2_grid))
poly_grid_pred <- predict(poly_model, newdata = data.frame(co2 = co2_grid))

knn_optimal_model <- knnreg(x = x_train, y = y_train, k = optimal_k_cv)
knn_grid_pred <- predict(knn_optimal_model, newdata = co2_grid_matrix)

nw_grid_pred <- nadaraya_watson(
  x_train = as.vector(x_train),
  y_train = y_train,
  x_test = co2_grid,
  bandwidth = optimal_h_cv
)

# Combine all predictions
all_predictions <- bind_rows(
  data.frame(co2 = co2_grid, prediction = ols_grid_pred, Method = "Linear"),
  data.frame(co2 = co2_grid, prediction = poly_grid_pred, Method = "Polynomial"),
  data.frame(co2 = co2_grid, prediction = knn_grid_pred, Method = "k-NN"),
  data.frame(co2 = co2_grid, prediction = nw_grid_pred, Method = "Nadaraya-Watson")
)

# Plot
ggplot() +
  geom_point(data = climate_data, 
             aes(x = co2, y = temperature_anomaly),
             alpha = 0.1, colour = "gray50") +
  geom_line(data = all_predictions,
            aes(x = co2, y = prediction, colour = Method),
            size = 1) +
  scale_colour_manual(values = c("Linear" = "red",
                                  "Polynomial" = "blue",
                                  "k-NN" = "green",
                                  "Nadaraya-Watson" = "purple")) +
  labs(
    title = "Comparison of Regression Methods",
    x = expression(CO[2]~Concentration~(ppm)),
    y = expression(Temperature~Anomaly~(degree*C))
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")
```

**Screenshot Suggestion 12**: *Add comprehensive plot comparing all fitted curves*
```
üì∏ [Screenshot: all_methods_curves.png]
Caption: Figure 12: Fitted curves for all four regression methods on climate data
```

### 3. Method Characteristics Summary

| **Method** | **RMSE** | **Flexibility** | **Interpretability** | **Computation Time** |
|------------|----------|-----------------|---------------------|---------------------|
| Linear Regression | 0.298 | Low | High | Very fast |
| Polynomial (deg 3) | **0.155** | Medium | Medium | Fast |
| k-NN (k=30) | 0.157 | High | Low | Medium |
| Nadaraya-Watson (h=2.0) | **0.155** | High | Medium | Slow (looped) |

---

## üí° Insights & Findings

### 1. Nonlinearity in Climate Data

**Key Finding**: The CO‚ÇÇ-temperature relationship is **clearly nonlinear**, with parametric methods (linear regression) performing substantially worse than nonparametric approaches.

```
Linear RMSE: 0.298
Nonparametric RMSE: 0.155
Improvement: 48% reduction in prediction error
```

**Screenshot Suggestion 13**: *Add residual plot comparing linear vs nonparametric fits*
```
üì∏ [Screenshot: residual_comparison.png]
Caption: Figure 13: Residual patterns revealing systematic error in linear model
```

### 2. Three Distinct Regimes

The optimal Nadaraya-Watson fit (h = 2.0) reveals three distinct phases:

| **CO‚ÇÇ Range** | **Pattern** | **Climate Interpretation** |
|---------------|-------------|---------------------------|
| **315-350 ppm** | Gradual slope | Early industrial period, slower warming |
| **350-400 ppm** | Steeper slope | Accelerating warming, feedback loops |
| **400-450 ppm** | Plateauing? | Possible saturation or recent data artifact |

**Screenshot Suggestion 14**: *Add annotated plot highlighting the three regimes*
```
üì∏ [Screenshot: climate_regimes.png]
Caption: Figure 14: Three distinct regimes in CO‚ÇÇ-temperature relationship revealed by nonparametric methods
```

### 3. Comparison with Climate Science Literature

| **Source** | **Finding** | **Matches Our Analysis?** |
|------------|-------------|---------------------------|
| IPCC AR6 | Nonlinear response to CO‚ÇÇ forcing | ‚úì Yes‚Äînonlinear pattern detected |
| Hansen et al. 2010 | Acceleration post-1980 | ‚úì Yes‚Äîsteeper slope >350 ppm |
| Climate sensitivity studies | Logarithmic relationship | ‚úì Consistent with our findings |

### 4. Why Linear Models Fail

```r
# Calculate linear model residuals
linear_residuals <- residuals(ols_model)

# Test for pattern in residuals
residual_lm <- lm(linear_residuals ~ poly(train_data$co2, 2))
summary(residual_lm)$r.squared
```
```
R-squared of quadratic pattern in residuals: 0.324
```

**Interpretation**: 32.4% of residual variation is explained by quadratic pattern‚Äîclear evidence of misspecification.

### 5. Parameter Sensitivity

| **Method** | **Optimal Parameter** | **Range Tested** | **Sensitivity** |
|------------|----------------------|------------------|-----------------|
| k-NN | k = 30 | 1-100 | Low (stable 20-50) |
| Nadaraya-Watson | h = 2.02 | 2-47 | High (sharp optimum) |

---

## üß≠ Climate Science Recommendations

### For Climate Researchers

#### 1. üìä Move Beyond Linear Assumptions

**Finding**: Linear models systematically underestimate warming at high CO‚ÇÇ levels.

**Recommendation**: Use nonparametric methods as **exploratory tools** before committing to parametric forms.

```r
# Recommended workflow
exploratory_analysis <- function(data) {
  # 1. Start with visualization
  ggplot(data, aes(x = co2, y = temperature_anomaly)) +
    geom_point() +
    geom_smooth(method = "loess", se = TRUE)
  
  # 2. Fit nonparametric benchmark
  nw_fit <- nadaraya_watson(data$co2, data$temperature_anomaly, 
                            data$co2, bandwidth = 2.0)
  
  # 3. Compare with candidate parametric models
  # If parametric fits within confidence bands, use simpler model
}
```

#### 2. üî¨ Focus on Threshold Effects

The change in slope around **350-360 ppm** warrants investigation:
- Is this a genuine climate feedback threshold?
- Does it correspond to known tipping points?
- Collect more data in this range

#### 3. üìà Improve Data Collection in Key Regions

| **CO‚ÇÇ Range** | **Current Observations** | **Recommendation** |
|---------------|-------------------------|-------------------|
| 315-330 ppm | Many | Sufficient |
| 330-360 ppm | Moderate | Maintain |
| **360-400 ppm** | **Few** | **Increase monitoring** |
| 400-450 ppm | Moderate | Maintain |

**Screenshot Suggestion 15**: *Add data density plot showing observation distribution*
```
üì∏ [Screenshot: data_density.png]
Caption: Figure 15: Density of observations across CO‚ÇÇ range‚Äînote sparse region at 360-400 ppm
```

### For Statistical Educators

#### 1. üéì Teaching the Bias-Variance Tradeoff

Use this dataset to demonstrate:
- **k=1**: Perfect training fit, poor test performance (overfitting)
- **k=30**: Optimal balance
- **k=100**: Oversmoothed, misses patterns (underfitting)

#### 2. üìù Practical Exercises

```r
# Exercise: Implement your own kernel
student_kernel <- function(u) {
  # Try different kernels:
  # - Uniform: ifelse(abs(u) <= 1, 0.5, 0)
  # - Epanechnikov: ifelse(abs(u) <= 1, 0.75 * (1 - u^2), 0)
  # - Gaussian: (1/sqrt(2*pi)) * exp(-u^2/2)
}

# Compare results with different kernels
```

#### 3. üîÑ Cross-Validation Demonstration

Show students how CV error changes with parameters:
- Plot CV error curves
- Highlight the minimum
- Discuss parameter uncertainty (SE bands)

---

## üîÆ Future Work

### 1. üß† Advanced Kernel Methods

```r
# Local polynomial regression (LOESS)
library(loess)
loess_fit <- loess(temperature_anomaly ~ co2, data = climate_data, span = 0.3)

# Compare with Nadaraya-Watson
# Local polynomials correct bias at boundaries
```

### 2. üìä Multidimensional Extensions

```r
# Add additional predictors (if available)
# - Time (year)
# - Solar activity
# - Volcanic aerosol index

# Multivariate kernel regression
# Challenge: Curse of dimensionality
```

### 3. ü§ñ Hybrid Approaches

```r
# Semi-parametric models
# Parametric for known physics + nonparametric for unknown

# Example: 
# temperature ~ Œ≤‚ÇÄ + Œ≤‚ÇÅ*log(CO‚ÇÇ) + g(time)
# where g() is estimated nonparametrically
```

### 4. üì± Interactive Shiny Application

```r
# Proposed Shiny app features:
# - Slider for k (k-NN) and bandwidth (NW)
# - Real-time curve updating
# - CV error display
# - Comparison with parametric models
```

**Screenshot Suggestion 16**: *Add mockup of proposed Shiny app interface*
```
üì∏ [Screenshot: shiny_mockup.png]
Caption: Figure 16: Concept for interactive Shiny app demonstrating nonparametric methods
```

### 5. üî¨ Uncertainty Quantification

```r
# Bootstrap confidence bands
bootstrap_nw <- function(data, B = 1000, bandwidth) {
  n <- nrow(data)
  fits <- matrix(NA, nrow = length(co2_grid), ncol = B)
  
  for(b in 1:B) {
    # Bootstrap sample
    idx <- sample(1:n, n, replace = TRUE)
    boot_data <- data[idx, ]
    
    # Fit NW on bootstrap sample
    fits[, b] <- nadaraya_watson(boot_data$co2, boot_data$temperature_anomaly,
                                 co2_grid, bandwidth)
  }
  
  # Calculate pointwise confidence intervals
  cis <- apply(fits, 1, quantile, probs = c(0.025, 0.975))
  return(t(cis))
}
```

---

## üì• Repository Access

```bash
git clone https://github.com/yourusername/STAT312-Practicals.git
cd STAT312-Practicals/03-Nonparametric-Regression
```

### Files Included:
- `practical_5.Rmd` - Complete R Markdown document
- `practical_5.pdf` - Knitted output with all results
- `data/climate_data.csv` - Climate dataset (780 obs, 2 vars)

### Quick Start
```r
# In RStudio
setwd("path/to/03-Nonparametric-Regression")
rmarkdown::render("practical_5.Rmd")
```

---

## üôè Acknowledgements

- **Climate Research Community**: For making atmospheric CO‚ÇÇ data publicly available
- **Kernel Methods Pioneers**: Nadaraya (1964), Watson (1964)
- **R Core Team**: For maintaining the ecosystem
- **STAT312 Students**: 2024-2025 cohorts for feedback on method comparisons

---

## üìä Citation

If using this module in your teaching or research:

```
[Your Name] (2025). Module 03: Nonparametric Regression.
STAT312: Advanced Data Analysis in R. Nelson Mandela University.
https://github.com/yourusername/STAT312-Practicals
```

---

## üìã Summary Table: Nonparametric Methods in Climate Science

| **Aspect** | **k-NN Regression** | **Nadaraya-Watson** | **Why It Matters** |
|------------|---------------------|---------------------|-------------------|
| **Tuning Parameter** | k (neighbours) | h (bandwidth) | Controls flexibility |
| **Optimal Value** | k = 30 | h = 2.02 | Balances bias-variance |
| **Test RMSE** | 0.157 | **0.155** | Both outperform linear |
| **Computation** | Fast (caret) | Slow (looped) | Trade-off for custom implementation |
| **Strengths** | Simple, intuitive | Smooth, continuous | Different tools for different needs |
| **Weaknesses** | Discrete steps | Boundary bias | Awareness improves application |

### Key Takeaways

1. **Linear models are insufficient** for climate data (RMSE nearly double)
2. **Nonlinear patterns** reveal three distinct regimes in CO‚ÇÇ-temperature relationship
3. **Parameter tuning matters**‚Äîcross-validation essential for optimal performance
4. **Both methods agree** on the underlying pattern, increasing confidence
5. **Implementation understanding** (like our NW function) deepens statistical intuition

---

**‚¨ÜÔ∏è [Back to Top](#-module-03-nonparametric-regression)**
